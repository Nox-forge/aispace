services:
  fine-tune-lab:
    build:
      context: https://github.com/Nox-forge/aispace.git#master:projects/fine-tune-lab
    container_name: fine-tune-lab
    restart: unless-stopped
    ports:
      - "8881:8881"
    environment:
      - OLLAMA_URL=http://host.docker.internal:8080
      - BASE_MODEL=llama3.2:3b
      - HF_BASE_MODEL=meta-llama/Llama-3.2-3B-Instruct
      - NVIDIA_VISIBLE_DEVICES=all
      - HF_HOME=/data/hf_cache
    volumes:
      - finetune-data:/data
      - hf-cache:/data/hf_cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    extra_hosts:
      - "host.docker.internal:host-gateway"

volumes:
  finetune-data:
  hf-cache:
